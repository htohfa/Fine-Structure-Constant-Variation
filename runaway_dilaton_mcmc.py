# -*- coding: utf-8 -*-
"""Runaway dilaton mcmc.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iY25WLZ8EDgLmiCuUIUZTTS9URkjENhO
"""


# Commented out IPython magic to ensure Python compatibility.
import numpy as np 
import random
from scipy.integrate import odeint
import matplotlib.pyplot as plt
import corner
from scipy.interpolate import interp1d
from numpy import array, arange
from scipy.optimize import minimize
import emcee
from numpy import genfromtxt
import sys
  


z = np.loadtxt("EM_1.dat")[:, 0]
alpha = np.loadtxt("EM_1.dat")[:, 1]
z2 = np.loadtxt("EM_2.dat")[:, 0]
alpha2 = np.loadtxt("EM_2.dat")[:, 1]
z3 = np.loadtxt("EM_3.dat")[:, 0]
alpha3 = np.loadtxt("EM_3.dat")[:, 1]

redshift_data=[]
alpha_eigenvalue =[]
for i in range(0,len(z)):
    if z[i]<1600:
        alpha_eigenvalue.append(alpha[i])
        redshift_data.append(z[i])
redshift_data2=[]
alpha_eigenvalue2 =[]
for i in range(0,len(z2)):
    if z2[i]<1600:
        alpha_eigenvalue2.append(alpha2[i])
        redshift_data2.append(z2[i])

redshift_data3=[]
alpha_eigenvalue3 =[]
for i in range(0,len(z)):
    if z[i]<1600:
        alpha_eigenvalue3.append(alpha3[i])
        redshift_data3.append(z3[i])

np.mean(alpha_eigenvalue)

interpolation= interp1d(redshift_data,alpha_eigenvalue, fill_value='extrapolate' )
interpolation2= interp1d(redshift_data2,alpha_eigenvalue2, fill_value='extrapolate' )
interpolation3= interp1d(redshift_data3,alpha_eigenvalue3, fill_value='extrapolate' )

#comaparable dataset 
redshift1=[]
rho1 =[]
for i in range(0,len(z)):
    if 1000<z[i]<1600:
        alpha_eigenvalue.append(alpha[i])
        redshift_data.append(z[i])
redshift_data2=[]
alpha_eigenvalue2 =[]
for i in range(0,len(z2)):
    if z2[i]<1600:
        alpha_eigenvalue2.append(alpha2[i])
        redshift_data2.append(z2[i])

redshift_data3=[]
alpha_eigenvalue3 =[]
for i in range(0,len(z)):
    if z[i]<1600:
        alpha_eigenvalue3.append(alpha3[i])
        redshift_data3.append(z3[i])

ref_values= [10**-4, .5*10**-8,-.5*10**2]

#the dynamic scalar field equation 
def f(p, z, a, c):
    x = p[0]
    U = p[1]
    dx = U     
    dU = -2.*U/((1.+z))+ ((1.+(.73)/(.3*(1+z)**3+.73))*(3.-((1.+z)*U)**2*(1+z)**2*U))/(2*(1+z)**4)+(np.exp(-c*(x-p[0]))*a*.3*(3.-((1.+z)*U)**2))/(2*(1+z)**4*(.04+.23+.73/((1+z)**3)+2.7*10**-5*(1+z)**4))    
    return array([dx, dU], float)

def rho_cal( a,bf,c):
  phi_0 = 0
  phi_1 = 0
  z0 =0           
  zf = 1600        
  N = 2000           
  h = (zf - z0)/N
  delta_alpha= []
  zpoints=[]
  zpoints = np.arange(z0, zf, h)
  a_ref =10**-4
  xpoints = []
  vpoints = []
  p = array([phi_0, phi_1], float)
  for z in zpoints:
      xpoints.append(p[0])
      vpoints.append(p[1])
      k1 = h * f(p, z, a_ref, c)
      k2 = h * f(p + 0.5*k1, z + 0.5*h, a_ref, c)
      k3 = h * f(p + 0.5*k2, z + 0.5*h, a_ref, c)
      k4 = h * f(p + k3, z + .5*h, a_ref, c)
      p = p + (k1 + 2*k2 + 2*k3 + k4)/6
  for i in range(0,1999):
      alpha = bf*c**2*(c*xpoints[0]- c*xpoints[i])
      delta_alpha.append(alpha)

  # refernce case   
  trapezoid_area=[]
  rho_ref=[]
  for k in range (0,1998):
      kth = interpolation(zpoints[k])*delta_alpha[k]
      kplus1th = interpolation(zpoints[k+1])*delta_alpha[k+1]
      area= .5*(kth+ kplus1th)*(zpoints[k+1]-zpoints[k])
      trapezoid_area.append(area)
  for i in range (0,len(trapezoid_area)-1):
      integral_ref = trapezoid_area[i]+trapezoid_area[i+1]
  normalized_rho_ref = integral_ref/(10**-4)

  trapezoid_area=[]
  rho_ref2=[]
  for k in range (0,1998):
      kth = interpolation2(zpoints[k])*delta_alpha[k]
      kplus1th = interpolation2(zpoints[k+1])*delta_alpha[k+1]
      area= .5*(kth+ kplus1th)*(zpoints[k+1]-zpoints[k])
      trapezoid_area.append(area)
  for i in range (0,len(trapezoid_area)-1):
      integral_ref2 = trapezoid_area[i]+trapezoid_area[i+1]
  normalized_rho_ref2 = integral_ref2/(10**-4)

  trapezoid_area=[]
  rho_ref3=[]
  for k in range (0,1998):
      kth = interpolation3(zpoints[k])*delta_alpha[k]
      kplus1th = interpolation3(zpoints[k+1])*delta_alpha[k+1]
      area= .5*(kth+ kplus1th)*(zpoints[k+1]-zpoints[k])
      trapezoid_area.append(area)
  for i in range (0,len(trapezoid_area)-1):
      integral_ref3 = trapezoid_area[i]+trapezoid_area[i+1]
  normalized_rho_ref3 = integral_ref3/(10**-4)

  
  #rho using linear comb
  delta_A= a-10**(-4)
  rho_a1 = delta_A*normalized_rho_ref
  rho_a2 = delta_A*normalized_rho_ref2
  rho_a3 = delta_A*normalized_rho_ref3

  rho_aPCA= rho_a1,rho_a2, rho_a3
   
  return rho_aPCA

rho_dat= [.017,.039,.062 ]

sigma = [.088, .147, .394]



def log_likelihood(theta, rho_data, rhoerr):
    a, bf, c = theta
    model = rho_cal(a,bf,c)
    sigma2 = [[1/rhoerr[0] ** 2,0,0], [0,1/rhoerr[1]**2,0], [0,0, 1/rhoerr[2]**2]]
    rho_matrix= [(model[0]- .017),
                 (model[1]- .039),
                 (model[2]- .062)]
    chi= np.matmul(np.matmul(np.transpose(rho_matrix),sigma2),rho_matrix) 
    #return chi*-.5 + log(sum (sigma2))
    #x= -.5* np.sum( np.matmul(rho_matrix,sigma2) + np.log(sigma2))
    return -.5*chi #talk to dan about the normalization term 

a_guess = .2*10**-4
bf_guess = .01
c_guess = -1
np.random.seed(42)
nll = lambda *args: -log_likelihood(*args)
initial = np.array([a_guess, bf_guess,c_guess]) + 0.1 * np.random.randn(3)
soln = minimize(nll, initial, args=(rho_dat, sigma))
a_ml, bf_ml, c_ml = soln.x
print(a_ml,bf_ml,c_ml)


def log_prior(theta):
    a, bf, c = theta
    if -1 < a < 1 and -2 < bf < 2 and -5 < c < 5:
        return 0.0
    return -np.inf

def log_prior(theta):
    a, bf, c = theta
    if -.1 < a < .1 and -1 < bf < 1 and -5 < c < 5:
        return 0.0
    return -np.inf

def log_probability(theta, rho_data, rho_err):
    lp = log_prior(theta)
    if not np.isfinite(lp):
        return -np.inf
    return lp + log_likelihood(theta, rho_data, rho_err)


pos =  soln.x + 1e-2 * np.random.randn(32, 3)
nwalkers, ndim = pos.shape

sampler = emcee.EnsembleSampler(nwalkers, ndim, log_probability, args=(rho_dat, sigma))
sampler.run_mcmc(pos,10000, progress=True);



fig, axes = plt.subplots(3, figsize=(10, 7), sharex=True)
samples = sampler.get_chain()
labels = ["a", "bf", "c"]
for i in range(ndim):
    ax = axes[i]
    ax.plot(samples[:, :, i], "k", alpha=0.3)
    ax.set_xlim(0, len(samples))
    ax.set_ylabel(labels[i])
    ax.yaxis.set_label_coords(-0.1, 0.5)

axes[-1].set_xlabel("step number");
plt.savefig("plot.pdf")

tau = sampler.get_autocorr_time()
print(tau)

flat_samples = sampler.get_chain(discard=100, thin=15, flat=True)
print(flat_samples.shape)


labels = ["a", "bf", "c"]
fig = corner.corner(
    flat_samples, labels=labels,levels=(0.68,0.95,0.99,)
    );
fig.savefig("Contour.pdf")


for i in range(ndim):
    mcmc = np.percentile(flat_samples[:, i], [16, 50, 84])
    q = np.diff(mcmc)
    txt = "\mathrm{{{3}}} = {0:.3f}_{{-{1:.3f}}}^{{{2:.3f}}}"
    txt = txt.format(mcmc[1], q[0], q[1], labels[i])
    display(Math(txt))
    print(txt)

